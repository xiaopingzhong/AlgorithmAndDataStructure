# 数据结构
## 含义
 (1)概念:数据在计算机内存中的组织形式
 ![数据结构综述](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20190804110913.png)
 (2)数据之间的关系--物理关系(连续或者不连续),逻辑关系(集合结构,线性结构,树形结构,图形结构)
## 数据结构API
  数据结构除了最基础的模型表示之外--还需要提供一组**对数据进行操作的方法**--也就是API
  API的组成部分:初始化,插入,遍历,删除,查找--对数据的操作
## 伪代码
   伪代码--高效的信息传递(作用)
# 算法分析
![算法分析的主要内容](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20190804105447.png)
影响时间复杂度是执行耗时和执行频次,
    (1)执行耗时根据系统硬件不同而不同--在这里我们都是假设在统一环境中--通常是类似c=a+b类的执行语句
    (2)执行频次:算法设计和数据规模
  **时间复杂度=执行耗时 * 执行频次**
# 时间复杂度
含义:数据的操作次数和数据规模的比例关系
大O表示法-->O order--只是其中一种的复杂度
![常用的时间复杂度-1](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20190804103617.png)
![常用的时间复杂度-比较](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20190804121924.png)
![时间复杂度的近似](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20190804121655.png)
 PS:
 (1)一般来说,O(nlogn)及其以下时间复杂度的算法是比较优秀的
 (2)实际可用的算法的时间复杂度都是指数级复杂度($2^n$)以下
 (3)O(1)常数级别的算法就是 无论数据规模有多大,每次最终的操作次数都是相同的,例如O(456)-->对应的是常数级别

## 时间换空间，空间换时间
空间换时间：比如典型的就是 python 中的集合（后面会讲到它的实现原理），虽然它比较浪费空间，但是却能用 O(1) 的时间复杂度来判重。
时间换空间：当我们空间不够用，典型的就是缓存失效算法，我们不可能缓存下无限容量的数据，就会使用一些缓存淘汰算法来保证空间可用。
## 例子
考虑计算一个 n * n 矩阵所有元素的和（如果你不知道矩阵，就理解为一个二维数组）：
$$ \begin{bmatrix} 0 & 1 & 2 \ 3 & 4 & 5 \ 6 & 7 & 8 \ \end{bmatrix} $$
这里列举两种方式:
```
# version1
total_sum = 0
for i in range(n):
    row_sum[i] = 0
    for j in range(n):
        row_sum[i] = row_sum[i] + matrix[i, j]
        total_sum = total_sum + matrix[i, j]

# version2
total_sum = 0
for i in range(n):
    row_sum[i] = 0
    for j in range(n):
        row_sum[i] = row_sum[i] + matrix[i, j]
    total_sum = total_sum + row_sum[i]    # 注意这里和上边的不同
```
v1 版本的关键操作在 j 循环里，两步加法操作--执行耗时(假设2s)，由于嵌套在第一个循环里，操作步骤是 $ 2s * n * n = 2n^2 s $。
v2 版本的 total_sum 只有 n 次操作，它的操作次数是 $ 1s * n * n +1s * n= n^2 + n $。其中`1s * n * n`是内部循环复杂度,`1s * n`则是外部循环复杂度
这里你可能还感觉不到它们有多大差别，因为计算机执行的太快了，但是当 n 增长特别快的时候，总的操作次数差距就很明显了
| n      | $ 2n^2 $       | $ n^2 +n $     |
| ------ | -------------- | -------------- |
| 10     | 200            | 110            |
| 100    | 20,000         | 10,100         |
| 1000   | 2,000,000      | 1,001,000      |
| 10000  | 200,000,000    | 100,010,000    |
| 100000 | 20,000,000,000 | 10,000,100,000 |

   其实对于具体的耗时,我们不怎么关注,但我们更关注该算法随着数据规模增大,算法所耗时的增长率(因此就会带来时间复杂度求近似的步骤)
   (通常我们不太关注每个算法具体执行了多少次，而更关心随着输入规模 n 的增加，算法运行时间将以什么速度增加)

 
 
 
